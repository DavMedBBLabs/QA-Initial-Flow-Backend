import os
import json
import requests
from typing import Tuple
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

class DeepSeekService:
    def __init__(self):
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://blackbird-labs.com",
            "X-Title": "RIWI QA Backend"
        }
    
    def refine_hu(self, title: str, description: str, acceptance_criteria: str = "", feature: str = "", module: str = "") -> Tuple[str, str]:
        if not title or len(title.strip()) < 5:
            raise Exception("El t√≠tulo de la HU es muy corto o est√° vac√≠o")
        
        print(f"ü§ñ Refinando HU con calidad completa:")
        print(f"   üìù T√≠tulo: {title}")
        print(f"   üìÑ Descripci√≥n: {len(description)} caracteres")
        print(f"   üè∑Ô∏è Feature: {feature}")
        print(f"   üì¶ M√≥dulo: {module}")
        
        prompt = f"""Eres un experto en Refinamiento de User Stories y QA con m√°s de 10 a√±os de experiencia. Tu tarea es refinar la siguiente historia de usuario aplicando metodolog√≠a de evaluaci√≥n de criticidad y generando criterios de aceptaci√≥n en formato Gherkin.

**INFORMACI√ìN DE LA HISTORIA DE USUARIO:**
- **T√≠tulo**: {title}
- **Descripci√≥n**: {description if description else "No se proporcion√≥ descripci√≥n detallada"}
- **Criterios originales**: {acceptance_criteria if acceptance_criteria else "No se proporcionaron criterios originales"}
- **Feature/√âpica**: {feature if feature else "No especificada"}
- **M√≥dulo del Sistema**: {module if module else "No especificado"}

**INSTRUCCIONES CR√çTICAS:**
1. DEBES generar una respuesta COMPLETA y DETALLADA de al menos 3000 caracteres
2. NUNCA generes respuestas cortas o ambiguas
3. SIEMPRE incluye los 5 niveles de criterios de aceptaci√≥n
4. CADA criterio debe ser espec√≠fico, medible y testeable
5. Esta informaci√≥n ser√° enviada a Azure DevOps para que los desarrolladores y testers la usen

**INSTRUCCIONES CR√çTICAS PARA M√öLTIPLES ESCENARIOS:**
1. **M√çNIMO 3 ESCENARIOS POR CADA CRITERIO DE ACEPTACI√ìN** - No negociable
2. **M√ÅXIMO ILIMITADO** - Genera tantos escenarios como consideres necesarios para cobertura completa
3. **DIVERSIDAD OBLIGATORIA** - Cada escenario debe cubrir un aspecto diferente (positivo, negativo, edge case, diferentes roles, etc.)
4. **COBERTURA EXHAUSTIVA** - Piensa en todos los posibles caminos, condiciones y casos de uso
5. **RESPUESTA ULTRA-DETALLADA** - M√≠nimo 5000 caracteres de contenido rico

**METODOLOG√çA DE GENERACI√ìN DE ESCENARIOS:**
- **Escenario Principal**: Happy path, flujo ideal
- **Escenarios Alternativos**: Diferentes caminos v√°lidos
- **Escenarios de Validaci√≥n**: Reglas de negocio, restricciones
- **Escenarios de Error**: Casos negativos, fallos esperados
- **Escenarios Edge**: Casos l√≠mite, condiciones extremas
- **Escenarios de Roles**: Diferentes tipos de usuarios
- **Escenarios de Estado**: Diferentes estados del sistema
- **Escenarios de Integraci√≥n**: Interacciones con otros componentes


**PROCESO OBLIGATORIO:**

1. **EVAL√öA LA CRITICIDAD** (5 criterios de 1-5):
   - Impacto Negocio: ¬øQu√© tan cr√≠tico es para el negocio?
   - Frecuencia Uso: ¬øQu√© tan seguido se usa?
   - Complejidad T√©cnica: ¬øQu√© tan complejo es implementar?
   - Impacto de Falla: ¬øQu√© tan grave es si falla?
   - Novedad: ¬øQu√© tan nueva es la funcionalidad?

2. **APLICA ESTRATEGIA SEG√öN CRITICIDAD:**
   - üî¥ CR√çTICA (20-25 pts): Cobertura exhaustiva con casos edge
   - üü† ALTA (16-19 pts): Cobertura optimizada con validaciones
   - üü° MEDIA (11-15 pts): Cobertura b√°sica con flujo principal
   - üü¢ BAJA (5-10 pts): Cobertura m√≠nima pero completa

3. **GENERA CRITERIOS DETALLADOS EN 5 NIVELES OBLIGATORIOS:**

## EVALUACI√ìN AUTOM√ÅTICA DE CRITICIDAD
**Impacto Negocio**: [X]/5 - [Justificaci√≥n detallada de por qu√© este puntaje]
**Frecuencia Uso**: [X]/5 - [Justificaci√≥n detallada de por qu√© este puntaje]
**Complejidad T√©cnica**: [X]/5 - [Justificaci√≥n detallada de por qu√© este puntaje]
**Impacto de Falla**: [X]/5 - [Justificaci√≥n detallada de por qu√© este puntaje]
**Novedad**: [X]/5 - [Justificaci√≥n detallada de por qu√© este puntaje]
**PUNTUACI√ìN TOTAL**: [X]/25
**CLASIFICACI√ìN**: üî¥/üü†/üü°/üü¢ [CR√çTICA/ALTA/MEDIA/BAJA]
**ESTRATEGIA**: [Descripci√≥n detallada del enfoque de testing y cobertura]

## HISTORIA DE USUARIO REFINADA
**Como** [rol espec√≠fico], **quiero** [funcionalidad detallada], **para** [valor/beneficio concreto y medible].

**User Role:** [Definir claramente el rol del usuario]
**Business Value:** [Explicar el valor de negocio espec√≠fico]

**Pasos o User Flow Detallado:**
1. [Paso 1 - Acci√≥n espec√≠fica del usuario]
2. [Paso 2 - Respuesta del sistema]
3. [Paso 3 - Validaci√≥n o confirmaci√≥n]
4. [Paso 4 - Resultado final]
5. [Pasos adicionales si son necesarios]

## CRITERIOS DE ACEPTACI√ìN DETALLADOS

### 1. Intenci√≥n Macro (Propuesta de Valor)
**Escenario**: [Descripci√≥n clara del escenario de valor principal]
**Dado** que [condici√≥n inicial espec√≠fica y medible]
**Cuando** [acci√≥n del usuario detallada]
**Entonces** [resultado esperado espec√≠fico y verificable]
**Y** [condiciones adicionales de √©xito]
**ModoVerificaci√≥n**: [Manual/Autom√°tico con detalles espec√≠ficos]

### 2. Flujo Funcional Completo
**Escenario**: [Descripci√≥n del flujo end-to-end completo]
**Dado** que [precondici√≥n del sistema y datos]
**Cuando** [secuencia de acciones paso a paso]
**Entonces** [resultado del flujo completo]
**Y** [validaciones de integridad de datos]
**Y** [confirmaciones de estado del sistema]
**ModoVerificaci√≥n**: [Manual/Autom√°tico con casos de prueba espec√≠ficos]

### 3. Interacci√≥n con Componentes de Interfaz
**Escenario**: [Descripci√≥n detallada de la interacci√≥n UI/UX]
**Dado** que [estado espec√≠fico de la interfaz]
**Cuando** [interacci√≥n espec√≠fica del usuario]
**Entonces** [comportamiento esperado de la UI]
**Y** [cambios visuales espec√≠ficos]
**Y** [feedback al usuario]
**ModoVerificaci√≥n**: [Manual con casos de usabilidad espec√≠ficos]

### 4. Validaci√≥n de Datos y Reglas de Negocio
**Escenario**: [Descripci√≥n de todas las validaciones necesarias]
**Dado** que [datos de entrada espec√≠ficos]
**Cuando** [validaci√≥n ejecutada por el sistema]
**Entonces** [resultado de validaci√≥n espec√≠fico]
**Y** [manejo de errores detallado]
**Y** [mensajes de error espec√≠ficos]
**ModoVerificaci√≥n**: [Autom√°tico con casos de prueba de validaci√≥n]

### 5. Casos L√≠mite y Manejo de Errores
**Escenario**: [Descripci√≥n de casos edge y errores]
**Dado** que [condici√≥n l√≠mite espec√≠fica]
**Cuando** [acci√≥n en caso l√≠mite]
**Entonces** [comportamiento esperado del sistema]
**Y** [manejo graceful de errores]
**Y** [logging y monitoreo de errores]
**ModoVerificaci√≥n**: [Autom√°tico con casos de prueba negativos]

## CONSIDERACIONES T√âCNICAS
- [Tecnolog√≠as espec√≠ficas a utilizar]
- [Patrones de dise√±o recomendados]
- [Consideraciones de rendimiento]
- [Aspectos de seguridad]
- [Integraciones necesarias]

## CRITERIOS DE DONE
- [Criterio t√©cnico espec√≠fico 1]
- [Criterio de testing espec√≠fico 2]
- [Criterio de documentaci√≥n espec√≠fico 3]
- [Criterio de despliegue espec√≠fico 4]
- [Criterio de validaci√≥n de usuario espec√≠fico 5]

**RECORDATORIO CR√çTICO**: 
- Esta respuesta DEBE ser COMPLETA y DETALLADA (m√≠nimo 3000 caracteres)
- TODOS los criterios deben ser espec√≠ficos y testeables
- NUNCA generes respuestas ambiguas o incompletas
- Esta informaci√≥n ser√° usada por desarrolladores y testers
- Incluye SIEMPRE los 5 niveles de criterios de aceptaci√≥n"""

        payload = {
            "model": "mistralai/mistral-small-3.2-24b-instruct",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 8000,
            "temperature": 0.3
        }
        
        print(f"üöÄ Enviando request de alta calidad a Gemma...")
        print(f"   üìä Max tokens: {payload['max_tokens']}")
        print(f"   üìù Prompt length: {len(prompt)} characters")
        
        try:
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=90)
            
            if response.status_code != 200:
                print(f"‚ùå Gemma API error: {response.status_code}")
                print(f"‚ùå Response: {response.text}")
                raise Exception(f"Gemma API error: {response.status_code}")
            
            result = response.json()
            
            if 'choices' not in result or not result['choices']:
                raise Exception("Invalid API response format")
            
            content = result['choices'][0]['message']['content']
            
            print(f"‚úÖ Gemma response received:")
            print(f"   üìè Content length: {len(content)} characters")
            
            print(f"   üìÑ Content preview (primeros 500 chars):")
            print(f"   {content[:500]}...")
            
            possible_plain_markers = [
                "## CONSIDERACIONES T√âCNICAS",
                "## CRITERIOS DE DONE",
                "CONSIDERACIONES T√âCNICAS",
                "CRITERIOS DE DONE"
            ]
            
            plain_text_start = -1
            
            for marker in possible_plain_markers:
                pos = content.find(marker)
                if pos != -1:
                    plain_text_start = pos
                    print(f"   ‚úÖ Found separator marker: '{marker}' at position {pos}")
                    break
            
            print(f"   üìç Separator position: {plain_text_start}")
            
            plain_text = content.strip()
            markdown_text = content.strip()
            
            print(f"‚úÖ Using full content for both fields:")
            print(f"   üìù Plain text: {len(plain_text)} characters")
            print(f"   üìã Markdown: {len(markdown_text)} characters")
            
            if len(plain_text) < 1000:
                print(f"‚ö†Ô∏è WARNING: Contenido muy corto ({len(plain_text)} chars)")
                fallback = f"""
## EVALUACI√ìN AUTOM√ÅTICA DE CRITICIDAD
**Impacto Negocio**: 4/5 - Funcionalidad importante para el negocio
**Frecuencia Uso**: 3/5 - Uso regular por parte de los usuarios  
**Complejidad T√©cnica**: 3/5 - Implementaci√≥n de complejidad media
**Impacto de Falla**: 4/5 - Falla afectar√≠a significativamente a los usuarios
**Novedad**: 2/5 - Funcionalidad conocida con patrones establecidos
**PUNTUACI√ìN TOTAL**: 16/25
**CLASIFICACI√ìN**: üü† ALTA

## HISTORIA DE USUARIO REFINADA
{title}

{content}

## CONSIDERACIONES T√âCNICAS
- Implementar validaciones del lado cliente y servidor
- Considerar rendimiento para grandes vol√∫menes de datos
- Asegurar compatibilidad con diferentes navegadores

## CRITERIOS DE DONE
- Funcionalidad implementada y probada
- Validaciones funcionando correctamente
- Documentaci√≥n actualizada
"""
                plain_text = fallback
                markdown_text = fallback
            
            return plain_text, markdown_text
            
        except Exception as e:
            print(f"‚ùå Error during refinement: {str(e)}")
            raise Exception(f"Error durante el refinamiento: {str(e)}")
    
    def re_refine_hu(self, feedback: str, original_response: str) -> tuple:
        prompt = f"""Eres un experto en Refinamiento de User Stories y QA. Tu tarea es RE-REFINAR una historia de usuario que fue RECHAZADA por un QA. Debes aplicar espec√≠ficamente el feedback recibido para corregir los problemas identificados.

**HISTORIA DE USUARIO ORIGINAL REFINADA:**
{original_response}

**FEEDBACK DEL QA (MOTIVO DE RECHAZO):**
{feedback}

**PROCESO DE RE-REFINAMIENTO:**

1. **ANALIZA EL FEEDBACK DEL QA:**
   - Lee cuidadosamente cada observaci√≥n del QA
   - Identifica los problemas espec√≠ficos se√±alados
   - Determina qu√© secciones necesitan correcci√≥n

2. **APLICA LAS CORRECCIONES ESPEC√çFICAS:**
   - Corrige cada punto mencionado en el feedback
   - Mant√©n todo lo que NO fue criticado
   - Mejora solo las √°reas problem√°ticas identificadas

3. **CONSERVA LA ESTRUCTURA EXITOSA:**
   - Mant√©n el formato Gherkin y estructura de 5 niveles
   - Preserva la evaluaci√≥n de criticidad si no fue cuestionada
   - Conserva los aspectos que funcionaron bien

**FORMATO DE SALIDA REQUERIDO:**

## AN√ÅLISIS DEL FEEDBACK DEL QA
**Problemas identificados por el QA:**
- [Problema 1 espec√≠fico del feedback]
- [Problema 2 espec√≠fico del feedback]
- [Problema 3 espec√≠fico del feedback]

**Correcciones aplicadas:**
- [Correcci√≥n 1 para abordar el problema 1]
- [Correcci√≥n 2 para abordar el problema 2]
- [Correcci√≥n 3 para abordar el problema 3]

---

## HISTORIA DE USUARIO CORREGIDA
[Mant√©n la estructura original pero corrige seg√∫n el feedback]

**IMPORTANTE: Solo modifica las secciones que el QA se√±al√≥ como problem√°ticas. Mant√©n todo lo dem√°s igual.**

---

## FORMATO TEXTO PLANO
[Resumen conciso de los criterios corregidos en texto plano]

## FORMATO MARKDOWN
[Versi√≥n formateada en Markdown corregida]

**INSTRUCCIONES CR√çTICAS**: 
- SOLO cambia lo que el QA espec√≠ficamente critic√≥
- NO re-hagas toda la historia de usuario
- APLICA cada sugerencia del feedback de manera directa
- MANT√âN la estructura y formato original
- CONSERVA todo lo que no fue mencionado como problem√°tico"""

        payload = {
            "model": "mistralai/mistral-small-3.2-24b-instruct",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 8000,
            "temperature": 0.3
        }
        
        print(f"ü§ñ Re-refining with Gemma using compatible configuration...")
        response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=90)
        
        if response.status_code != 200:
            print(f"‚ùå Gemma API error: {response.status_code} - {response.text}")
            raise Exception(f"Gemma API error: {response.status_code}")
        
        result = response.json()
        content = result['choices'][0]['message']['content']
        print(f"‚úÖ Re-refinement completed with {len(content)} characters")
        
        try:
            plain_text_start = content.find("## FORMATO TEXTO PLANO")
            markdown_start = content.find("## FORMATO MARKDOWN")
            
            if plain_text_start != -1 and markdown_start != -1:
                plain_text = content[plain_text_start + len("## FORMATO TEXTO PLANO"):markdown_start].strip()
                markdown_text = content[markdown_start + len("## FORMATO MARKDOWN"):].strip()
            else:
                plain_text = content
                markdown_text = content
        except Exception as e:
            print(f"‚ö†Ô∏è Error parsing response sections: {e}")
            plain_text = content
            markdown_text = content
        
        return plain_text, markdown_text    

    def generate_xray_tests(self, refined_response: str, xray_path: str, azure_id: str) -> dict:
        """
        Genera casos de test en formato XRay basados en la respuesta refinada de la HU
        y los clasifica autom√°ticamente por criticidad si la IA no los clasifica
        CON REINTENTOS AUTOM√ÅTICOS Y MANEJO ROBUSTO DE ERRORES
        """
        
        # Extraer el n√∫mero de HU para usar en la carpeta
        hu_number = azure_id.replace('HU-', '') if 'HU-' in azure_id else azure_id
        
        prompt = f"""Eres un experto QA especializado en generaci√≥n de casos de test. Tu tarea es generar casos de test en formato XRay/Jira basados en la Historia de Usuario refinada proporcionada.

**HISTORIA DE USUARIO REFINADA:**
{{refined_response}}

**INFORMACI√ìN DEL TEST:**
- **Ruta XRay**: {{xray_path}}
- **HU ID**: {{azure_id}}

**INSTRUCCIONES PARA GENERACI√ìN DE TESTS:**

1. **ANALIZA LA HU REFINADA**: Identifica todos los criterios de aceptaci√≥n, escenarios principales, casos edge y validaciones.

2. GENERA LA MAYOR CANTIDAD POSIBLE DE CASOS DE TEST.
   ‚Ä¢ Cubre flujo principal, validaciones, casos l√≠mite, escenarios negativos, manejo de errores, UI/UX, m√≥vil, red y seguridad.  
   ‚Ä¢ Procura un caso de test por cada criterio/escenario identificado.

3. **FORMATO DE SALIDA REQUERIDO**  
Devuelve **UN OBJETO JSON** con las tres claves siguientes; cada clave contiene una lista de test cases:

```json
{{
  "criticos": [
    {{
      "testtype": "Manual",
      "fields": {{
        "summary": "T√≠tulo corto cr√≠tico",
        "description": "Descripci√≥n del caso cr√≠tico",
        "project": {{ "key": "DEUN" }},
        "issuetype": {{ "name": "Test" }}
      }},
      "steps": [
        {{ "action": "DADO ‚Ä¶", "data": "‚Ä¶", "result": "ENTONCES ‚Ä¶" }},
        {{ "action": "CUANDO ‚Ä¶", "data": "‚Ä¶", "result": "‚Ä¶" }}
      ],
      "testPath": "{{xray_path}}/Cr√≠ticos",
      "xray_test_sets": ["DEUN-319"]
    }}
  ],
  "importantes": [
    {{
      "testtype": "Manual",
      "fields": {{ ... }},
      "steps": [ /* ‚Ä¶ */ ],
      "testPath": "{{xray_path}}/Importantes",
      "xray_test_sets": ["DEUN-319"]
    }}
  ],
  "opcionales": [
    {{
      "testtype": "Manual",
      "fields": {{ "summary": "", "description": "", ‚Ä¶ }},
      "steps": [ /* ‚Ä¶ */ ],
      "testPath": "{{xray_path}}/Opcionales",
      "xray_test_sets": ["DEUN-319"]
    }}
  ]
}}

4. **REQUISITOS ESPEC√çFICOS**:
   - Usa sintaxis Gherkin (DADO/CUANDO/ENTONCES) en los steps
   - Cada test debe ser espec√≠fico y ejecutable
   - Include datos de entrada realistas cuando sea necesario
   - Los resultados esperados deben ser verificables
   - Summary debe ser conciso pero descriptivo
   - Description debe explicar qu√© se est√° probando

5. **EJEMPLOS DE BUENOS TEST CASES**:
   - "Verificar login exitoso con credenciales v√°lidas"
   - "Validar mensaje de error con email inv√°lido"
   - "Comprobar l√≠mite m√°ximo de caracteres en campo nombre"
   - "Verificar redireccionamiento despu√©s de acci√≥n exitosa"

**IMPORTANTE**: 
   - Responde √öNICAMENTE con el objeto JSON mostrado arriba; sin texto adicional
   - NO incluyas texto adicional, explicaciones o comentarios
   - Aseg√∫rate de que el JSON sea v√°lido y parseable
   - Cada test debe estar basado en los criterios de la HU refinada
   - Los tests deben ser ejecutables manualmente por un QA

**RECUERDA**: Tu respuesta debe ser SOLO el array JSON de casos de test, nada m√°s"""
        payload = {
            "model": "mistralai/mistral-small-3.2-24b-instruct", 
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 8000,
            "temperature": 0.2  # Menos creatividad para m√°s precisi√≥n en formato JSON
        }

        print(f"üß™ Generando casos de test para {azure_id}...")
        print(f"   üìÇ Ruta XRay: {xray_path}")
        print(f"   üìè Contenido refinado: {len(refined_response)} caracteres")

        # ‚úÖ CONFIGURACI√ìN DE REINTENTOS
        max_attempts = 3
        base_timeout = 60  # Timeout inicial m√°s alto
        
        for attempt in range(1, max_attempts + 1):
            try:
                print(f"üîÑ Intento {attempt}/{max_attempts} - Conectando con IA...")
                
                # Timeout progresivo: 60s, 90s, 120s
                current_timeout = base_timeout + (attempt - 1) * 30
                print(f"   ‚è±Ô∏è Timeout configurado: {current_timeout}s")
                
                # ‚úÖ CONFIGURACI√ìN ROBUSTA DE REQUESTS
                session = requests.Session()
                session.headers.update(self.headers)
                
                # Configurar adaptadores con reintentos a nivel de conexi√≥n
                from requests.adapters import HTTPAdapter
                from urllib3.util.retry import Retry
                
                retry_strategy = Retry(
                    total=2,  # Reintentos a nivel de urllib3
                    status_forcelist=[429, 500, 502, 503, 504],
                    backoff_factor=1,
                    raise_on_status=False
                )
                
                adapter = HTTPAdapter(max_retries=retry_strategy)
                session.mount("http://", adapter)
                session.mount("https://", adapter)
                
                response = session.post(
                    self.base_url, 
                    json=payload, 
                    timeout=current_timeout,
                    verify=True,  # Verificar SSL
                    stream=False  # No usar streaming
                )
                
                print(f"   üì° Respuesta recibida: {response.status_code}")
                
                if response.status_code != 200:
                    error_msg = f"API error: {response.status_code}"
                    if hasattr(response, 'text'):
                        error_msg += f" - {response.text[:200]}"
                    
                    if attempt < max_attempts:
                        print(f"‚ùå {error_msg}")
                        print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                        import time
                        time.sleep(attempt * 2)  # Backoff exponencial
                        continue
                    else:
                        raise Exception(f"Error en API de Gemma despu√©s de {max_attempts} intentos: {error_msg}")

                result = response.json()
                
                if 'choices' not in result or not result['choices']:
                    if attempt < max_attempts:
                        print(f"‚ùå Formato de respuesta inv√°lido")
                        print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                        import time
                        time.sleep(attempt * 2)
                        continue
                    else:
                        raise Exception("Formato de respuesta de API inv√°lido despu√©s de m√∫ltiples intentos")

                content = result['choices'][0]['message']['content'].strip()
                
                print(f"üìù Respuesta de IA recibida: {len(content)} caracteres")
                print(f"üìÑ Primeros 200 caracteres de la respuesta:")
                print(f"{content[:200]}...")
                
                # Limpiar el contenido JSON (remover markdown code blocks si existen)
                if content.startswith('```json'):
                    content = content.replace('```json', '').replace('```', '').strip()
                elif content.startswith('```'):
                    content = content.replace('```', '').strip()
                
                print(f"üßπ Contenido limpiado ({len(content)} chars)")
                
                # Intentar parsear el JSON
                try:
                    parsed_data = json.loads(content)
                    
                    print(f"üìä Tipo de respuesta recibida: {type(parsed_data)}")
                    
                    # ‚úÖ MANEJAR AMBOS FORMATOS: Lista simple o Objeto clasificado
                    if isinstance(parsed_data, list):
                        # Formato: lista de tests sin clasificar
                        print(f"üìã IA devolvi√≥ lista de {len(parsed_data)} tests (sin clasificar). Clasificando autom√°ticamente...")
                        
                        if len(parsed_data) == 0:
                            if attempt < max_attempts:
                                print(f"‚ùå No se generaron tests")
                                print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                                import time
                                time.sleep(attempt * 2)
                                continue
                            else:
                                raise ValueError("No se generaron casos de test despu√©s de m√∫ltiples intentos")
                        
                        # Clasificar autom√°ticamente los tests por posici√≥n/√≠ndice
                        total_tests = len(parsed_data)
                        criticos = []
                        importantes = []
                        opcionales = []
                        
                        # Distribuci√≥n autom√°tica basada en el total de tests
                        for i, test in enumerate(parsed_data):
                            # Validar que el test sea un objeto v√°lido
                            if not isinstance(test, dict):
                                raise ValueError(f"Test {i+1} no es un objeto v√°lido")
                            
                            # Actualizar la ruta de cada test para incluir el subdirectorio
                            if i < (total_tests // 3):  # Primeros tests ‚Üí Cr√≠ticos
                                test["testPath"] = f"{xray_path}/Cr√≠ticos"
                                criticos.append(test)
                            elif i < (2 * total_tests // 3):  # Tests medios ‚Üí Importantes
                                test["testPath"] = f"{xray_path}/Importantes"  
                                importantes.append(test)
                            else:  # √öltimos tests ‚Üí Opcionales
                                test["testPath"] = f"{xray_path}/Opcionales"
                                opcionales.append(test)
                        
                        classified_tests = {
                            "criticos": criticos,
                            "importantes": importantes, 
                            "opcionales": opcionales
                        }
                        
                        print(f"‚úÖ Clasificaci√≥n autom√°tica completada:")
                        print(f"   üî¥ Cr√≠ticos: {len(criticos)}")
                        print(f"   üü° Importantes: {len(importantes)}")
                        print(f"   üü¢ Opcionales: {len(opcionales)}")
                        
                    elif isinstance(parsed_data, dict):
                        # Formato: objeto con categor√≠as ya clasificado
                        print(f"‚úÖ IA devolvi√≥ formato clasificado correctamente")
                        
                        required_categories = ['criticos', 'importantes', 'opcionales']
                        for category in required_categories:
                            if category not in parsed_data:
                                print(f"‚ö†Ô∏è Falta la categor√≠a: {category}. Creando categor√≠a vac√≠a.")
                                parsed_data[category] = []
                            
                            if not isinstance(parsed_data[category], list):
                                print(f"‚ö†Ô∏è La categor√≠a {category} no es una lista. Convirtiendo.")
                                parsed_data[category] = []
                        
                        classified_tests = parsed_data
                        
                    else:
                        if attempt < max_attempts:
                            print(f"‚ùå Formato de respuesta no v√°lido: {type(parsed_data)}")
                            print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                            import time
                            time.sleep(attempt * 2)
                            continue
                        else:
                            raise ValueError(f"Formato de respuesta no v√°lido despu√©s de m√∫ltiples intentos: {type(parsed_data)}")
                    
                    # Contar tests por categor√≠a (funciona para ambos casos)
                    criticos_count = len(classified_tests['criticos'])
                    importantes_count = len(classified_tests['importantes'])
                    opcionales_count = len(classified_tests['opcionales'])
                    total_tests = criticos_count + importantes_count + opcionales_count
                    
                    if total_tests == 0:
                        if attempt < max_attempts:
                            print(f"‚ùå No se generaron casos de test v√°lidos")
                            print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                            import time
                            time.sleep(attempt * 2)
                            continue
                        else:
                            raise ValueError("No se generaron casos de test v√°lidos despu√©s de m√∫ltiples intentos")
                    
                    print(f"‚úÖ {total_tests} casos de test procesados y clasificados:")
                    print(f"   üî¥ Cr√≠ticos: {criticos_count}")
                    print(f"   üü° Importantes: {importantes_count}")
                    print(f"   üü¢ Opcionales: {opcionales_count}")
                    
                    # Validar estructura b√°sica de cada test en todas las categor√≠as
                    for category_name, tests in classified_tests.items():
                        for i, test in enumerate(tests):
                            if not isinstance(test, dict):
                                raise ValueError(f"Test {i+1} en categor√≠a {category_name} no es un objeto v√°lido")
                            
                            required_fields = ['testtype', 'fields', 'steps', 'testPath']
                            for field in required_fields:
                                if field not in test:
                                    raise ValueError(f"Test {i+1} en categor√≠a {category_name} falta campo requerido: {field}")
                    
                    print(f"‚úÖ Validaci√≥n de estructura completada para todas las categor√≠as")
                    print(f"‚úÖ Generaci√≥n exitosa en intento {attempt}/{max_attempts}")
                    
                    # Retornar estructura clasificada con metadatos
                    return {
                        'classified_tests': classified_tests,
                        'summary': {
                            'total_tests': total_tests,
                            'criticos': criticos_count,
                            'importantes': importantes_count,
                            'opcionales': opcionales_count
                        }
                    }
                    
                except json.JSONDecodeError as e:
                    if attempt < max_attempts:
                        print(f"‚ùå Error parseando JSON: {e}")
                        print(f"‚ùå Contenido problem√°tico: {content[:300]}...")
                        print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                        import time
                        time.sleep(attempt * 2)
                        continue
                    else:
                        print(f"‚ùå Error parseando JSON despu√©s de {max_attempts} intentos: {e}")
                        print(f"‚ùå Contenido final problem√°tico: {content[:500]}...")
                        raise Exception(f"La IA no gener√≥ un JSON v√°lido despu√©s de m√∫ltiples intentos: {str(e)}")
                
            except (requests.exceptions.ConnectionError, 
                    requests.exceptions.Timeout, 
                    requests.exceptions.RequestException,
                    ConnectionResetError) as e:
                
                if attempt < max_attempts:
                    print(f"‚ùå Error de conexi√≥n (intento {attempt}/{max_attempts}): {str(e)}")
                    print(f"   üîÑ Reintentando en {attempt * 3} segundos...")
                    import time
                    time.sleep(attempt * 3)  # Backoff m√°s largo para errores de conexi√≥n
                    continue
                else:
                    print(f"‚ùå Error de conexi√≥n persistente despu√©s de {max_attempts} intentos")
                    raise Exception(f"Fallo de conexi√≥n con la API despu√©s de {max_attempts} intentos: {str(e)}")
            
            except Exception as e:
                if attempt < max_attempts:
                    print(f"‚ùå Error inesperado (intento {attempt}/{max_attempts}): {str(e)}")
                    print(f"   üîÑ Reintentando en {attempt * 2} segundos...")
                    import time
                    time.sleep(attempt * 2)
                    continue
                else:
                    print(f"‚ùå Error persistente despu√©s de {max_attempts} intentos: {str(e)}")
                    raise Exception(f"Fallo en generaci√≥n de tests despu√©s de {max_attempts} intentos: {str(e)}")
        
        # Si llegamos aqu√≠, todos los intentos fallaron
        raise Exception(f"Fallo en generaci√≥n de tests despu√©s de {max_attempts} intentos con m√∫ltiples estrategias")
